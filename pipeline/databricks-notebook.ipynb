{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d5ebf834-6f38-4ad0-a2ac-375ee950ff90","showTitle":false,"title":""}},"source":["# Data prep for AzureML Pipeline\n","\n","This notebook executes as part of an AzureML Pipeline. This simply reads in a table and then writes it to the AzureML default blobstore."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"55bb87cc-6848-4038-8ef7-bd82cbe8cf59","showTitle":false,"title":""}},"outputs":[],"source":["# MLFlow logs will flow back to AzureML tracking service...\n","import mlflow\n","\n","mlflow.log_param(\"my\", \"param\")\n","mlflow.log_metric(\"my_metric\", 10.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f4a2bd94-451c-412b-a901-22d99d4cd0e8","showTitle":false,"title":""}},"outputs":[],"source":["df = spark.read.table(\"<MY-TABLE>\") ## change this to be a able you have stored in ADB \n","display(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"812e156a-1613-4803-97dd-421edd3eba73","showTitle":false,"title":""}},"outputs":[],"source":["output_location = \"/mnt/azuremlblobstore/\" + dbutils.widgets.getArgument(\"output_folder\")\n","print(output_location)\n","\n","df.write.mode(\"overwrite\").parquet(output_location)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"spark","notebookOrigID":4207745448269312,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
